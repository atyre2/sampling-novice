---
layout: page
title: Sampling
subtitle: Using spatial data in R
minutes: 10
---

```{r, include=FALSE}
source("tools/chunk-options.R")
opts_chunk$set(fig.path = "fig/load-spatial-data-")
.libPaths("C:/Users/Drew/Documents/R/win-library/3.2")
```

> ## Learning Objectives {.objectives}
>
> * Load spatial data into R
> * Intersect two polygon layers
> * Aggregate a raster across a list of spatial polygons

Once you have decided to use simple random sampling to choose your sites, how do you do it? There are two steps.

* Create or obtain a vector of all possible sampling units
* Use `sample()` to select the units you will use. 

This topic focuses on the first problem. 
In the following we load a dataset that provides a list of Nebraska Counties and their boundaries, and a 2nd dataset that has a raster of average annual precipitation across Nebraska. 
I obtained the original datasets from the [NRCS Geospatial Data Gateway][NGG]. However there are several steps involved in downloading data, so to ensure we all have the same data I have placed two zip files in a public folder on the UNL Box server. [The county boundaries are here][county_data] and [the annual average precipitation data are here][precip_data]. After you download these files extract them into a data subdirectory of your project directory. You did create a fresh project directory, right? Your directory tree should look like this:

![Directory structure](img/03-Directory_tree.png)

If it doesn't, just be sure to modify the paths 
in the code below so that it works. As always, I 
assume that you have started RStudio with a project,
and that the working directory is the project directory. 

We need three packages to work with shapefiles. The first is `sp`, which has the standard spatial 
datastructures for R.  
The second package, `rgdal` you need to read the shape files. To do the intersection of the two layers we need the `rgeos` package. So:

```{r}
#install.packages(c("sp", "rgeos, rgdal")) # if needed
library(sp)
library(rgeos)
library(rgdal)
```

We read in the two shapefiles using the layer names without the file extensions. 

```{r}
counties <- readOGR("data/government_units", layer = "county_nrcs_a_ne")
class(counties)
plot(counties)
annual_precip <- readOGR("data/climate/precipitation", layer = "precip1981_2010_a_ne")
class(annual_precip)
plot(annual_precip)
```

So we've managed to load in both layers. 
There are many functions that can read
ESRI shapefiles. `readOGR()` from package
`rgdal` has an important advantage however.
It also loads the *spatial projection*
information present in the file. The next
step is to use the precipitation data to add
some information to each of the polygons in
the county data. We also want to extract the
area of each county. The goal is to obtain a
`data.frame` object with one row for each 
county. It needs ID, area, and mean 
precipitation columns. 

```{r}
# extract the dataframe from counties
sample_frame <- as.data.frame(counties)
# take a look at the variables
names(sample_frame) # lots of stuff
sample_frame <- sample_frame[,c("OBJECTID","COUNTYNAME")]
# extract precipitation information for each county
head(over(counties, annual_precip, returnList = TRUE))
```

The function `over()` does all spatial intersection operations in `sp`. 
By setting `returnList = TRUE` `over()` returns a list with one 
component for each polygon in `counties`. Inside each component is the 
information from all polygons in `annual_precip` that intersect with 
that polygon of `counties`. So the first county intersects with 4 precipitation 
polygons with average annual precipitation between 17 and 20 inches. 
We need to aggregate those 4 values into one. If we leave `returnList = FALSE` (the default), we get just one value per row

```{r}
head(over(counties, annual_precip))
```

But the problem is that `over()` has just returned the precipitation of the first polygon.
A better way to do aggregate is to calculate the mean. 
`over()` has an argument `fn` that specifies the function to use for aggregation.

```{r, warning=1:2}
head(over(counties, annual_precip, fn = mean))
```

That's better. The warnings arise because the FIPS_S field is something that taking a mean of is nonsensical. 
I also just want one of those columns.

```{r, warning=FALSE}
sample_frame <- cbind(sample_frame,
                      Precip = over(counties, annual_precip, fn = mean)$PrecipInch)
```

I also want to extract the area of each county. To do this I pull out the list of polygons, 
and ask each polygon for it's area. These are S4 objects so the `@` operator
is used instead of `$`. 

```{r}
slotNames(counties)
slotNames(counties@polygons) # no slots ... 
class(counties@polygons)
class(counties@polygons[[1]])
slotNames(counties@polygons[[1]]) # there it is!

sample_frame$area <- sapply(counties@polygons, function(x) x@area)

head(sample_frame)
```

And now we're ready to pick a random sample!

```{r include=FALSE}
save(sample_frame,file="data/sample_frame.RData")
```


[NGG]: https://gdg.sc.egov.usda.gov/
[county_data]: https://unl.box.com/s/hhmwj9glyr785ixzdbo8fubkirljwg6c
[precip_data]: https://unl.box.com/s/l6tzuuc79kiyiyaytbgm0u05ea2teahu